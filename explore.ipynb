{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "from sklearn.preprocessing import LabelEncoder,LabelBinarizer,OneHotEncoder\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import sparse\n",
    "import scipy\n",
    "    \n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read five tables\n",
    "df_coupon_train=pd.read_csv('input/coupon_list_train.csv')\n",
    "df_coupon_test=pd.read_csv('input/coupon_list_test.csv')\n",
    "df_coupon_buy=pd.read_csv('input/coupon_detail_train.csv')\n",
    "df_coupon_visit=pd.read_csv('input/coupon_visit_train.csv')\n",
    "df_user=pd.read_csv('input/user_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_coupon_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_coupon_visit.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "script_path = os.path.abspath(os.path.dirname('__file__'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def extract_topn_item4user(df_itemUser_groupby_user, n=10, column=\"predict\", merge_column=\"COUPON_ID_hash\"):\n",
    "    '''\n",
    "    get top n row\n",
    "    :param pandas.DataFrame df:\n",
    "    :param int n:\n",
    "    :param str column:\n",
    "    :rtype: pandas.DataFrame\n",
    "    '''\n",
    "    return \" \".join(df_itemUser_groupby_user.sort_index(by=column)[-n:][merge_column])\n",
    "\n",
    "def binarizeFrame(df):\n",
    "    dic=df.T.to_dict().values()\n",
    "    vectorizer = DV( sparse = False )\n",
    "    vec_x_cat_train = vectorizer.fit_transform( dic)\n",
    "    return vec_x_cat_train\n",
    "\n",
    "class Get_Match_Pref(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    get user pref is match coupon area\n",
    "    '''\n",
    "\n",
    "    def get_feature_names(self):\n",
    "\n",
    "        return [self.__class__.__name__]\n",
    "\n",
    "    def fit(self, date_frame, y=None):\n",
    "        '''\n",
    "        fit\n",
    "\n",
    "        :param pandas.DataFrame: all data\n",
    "        :rtype: Get_Price_Rate\n",
    "        '''\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, date_frame):\n",
    "        '''\n",
    "        transform\n",
    "\n",
    "        :param pandas.DataFrame: all data\n",
    "        :rtype: array\n",
    "        '''\n",
    "        res_sr = date_frame[\"PREF_NAME\"] == date_frame[\"ken_name\"]\n",
    "\n",
    "        return res_sr.as_matrix()[None].T.astype(np.float)\n",
    "\n",
    "class Get_user_feature(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "\n",
    "        return [self.__class__.__name__]\n",
    "\n",
    "    def fit(self, data_frame, y=None):\n",
    "        '''\n",
    "        fit\n",
    "        :param pandas.DataFrame: all data\n",
    "        :rtype: Get_Price_Rate\n",
    "        '''\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df_coupon_train):\n",
    "        '''\n",
    "        transform\n",
    "        :param pandas.DataFrame: all data\n",
    "        :rtype: array\n",
    "        '''\n",
    "        le=LabelEncoder()\n",
    "        df_coupon_train['SEX_ID_Num']=le.fit_transform(df_coupon_train['SEX_ID'])\n",
    "        return df_coupon_train[['SEX_ID_Num', 'AGE','user_global_index']].as_matrix().astype(np.float)\n",
    "\n",
    "\n",
    "          \n",
    "class Get_coupon_feature(BaseEstimator, TransformerMixin):\n",
    "    def encode(self,v):\n",
    "        u = v.unique()\n",
    "        lm = len(u) + 1\n",
    "        d = {np.nan:lm, \"nan\": lm}  \n",
    "        for ii, iu in enumerate(u):\n",
    "            d[iu] = ii\n",
    "        return v.apply(lambda x: d.get(x, lm) ).values\n",
    "\n",
    "    def binarizeCategorical(self,df_coupon_cate):\n",
    "        oh=OneHotEncoder()\n",
    "        res_final = None\n",
    "        for i, col in enumerate(df_coupon_cate.columns):\n",
    "            #print col\n",
    "            res = self.encode(df_coupon_cate[col])\n",
    "            #print res.shape, np.unique(res), \n",
    "            #print len(df_coupon_train_cat[col].unique())\n",
    "            res = oh.fit_transform(res.reshape(len(res), 1))\n",
    "            res_final = res if res_final is None else sp.hstack((res_final, res))\n",
    "            #print res_final.shape\n",
    "        return res_final.todense()\n",
    "    \n",
    "    \n",
    "    def get_feature_names(self):\n",
    "\n",
    "        return [self.__class__.__name__]\n",
    "\n",
    "    def fit(self, df_coupon_train_cat, y=None):\n",
    "        '''\n",
    "        fit\n",
    "        :param pandas.DataFrame: all data\n",
    "        :rtype: Get_Price_Rate\n",
    "        '''\n",
    "        #df_coupon_train_cat.apply(lambda x: len(x.unique()))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df_coupon):\n",
    "        '''\n",
    "        transform\n",
    "        :param pandas.DataFrame: coupon property pandas data frame\n",
    "        :rtype: array\n",
    "        '''\n",
    "        #'COUPON_ID_hash',\n",
    "        df_coupon_nume=df_coupon[['PRICE_RATE', 'CATALOG_PRICE','DISCOUNT_PRICE','VALIDPERIOD','DISPPERIOD',\\\n",
    "                                              'USABLE_DATE_MON', 'USABLE_DATE_TUE',\\\n",
    "               'USABLE_DATE_WED', 'USABLE_DATE_THU', 'USABLE_DATE_FRI',\\\n",
    "               'USABLE_DATE_SAT', 'USABLE_DATE_SUN', 'USABLE_DATE_HOLIDAY','USABLE_DATE_BEFORE_HOLIDAY']]\n",
    "        df_coupon_cate=df_coupon[['CAPSULE_TEXT', 'GENRE_NAME', 'large_area_name', 'ken_name','small_area_name']]\n",
    "        \n",
    "        #sparse_m=binarizeCategorical(df_coupon_train_cat)\n",
    "        #sp.hstack(sparse_m,df_coupon_train_num.values)\n",
    "        df_coupon_binary=pd.DataFrame(self.binarizeCategorical(df_coupon_cate))  \n",
    "        df_coupon_combine=df_coupon_nume.join(df_coupon_binary)\n",
    "        #df_coupon_combine.set_index('COUPON_ID_hash',inplace=True)\n",
    "        df_coupon_combine=df_coupon_combine.fillna(0)\n",
    "        #ss=StandardScaler()\n",
    "        #df_coupon_train_combine.apply(lambda x:ss.fit_transform(x))\n",
    "        return df_coupon_combine.as_matrix().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.nonzero(pd.DataFrame(Xs)[162].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting rating matrix to be the number of buying\n",
    "df_rating=df_coupon_buy[[u'USER_ID_hash',u'COUPON_ID_hash','ITEM_COUNT']]\n",
    "# transform the hash code to natural index in df_coupon_train\n",
    "df_user['user_global_index']=df_user.index # all the users now has a unique index\n",
    "df_coupon_train['coupon_global_index']=df_coupon_train.index # all the coupons in training set now has a unique index\n",
    "#df_CouponProperty=pd.concat([df_coupon_train,df_coupon_test])\n",
    "\n",
    "# build up user global index and coupon global index as row and column index for the sparse-matrix\n",
    "user_id=df_user.set_index('USER_ID_hash').loc[df_rating['USER_ID_hash']]['user_global_index'].values\n",
    "coupon_id=df_coupon_train.set_index('COUPON_ID_hash').loc[df_rating['COUPON_ID_hash']]['coupon_global_index'].values\n",
    "num_item,num_user=len(df_coupon_train.COUPON_ID_hash.unique()),len(df_user.USER_ID_hash.unique())\n",
    "V=df_rating.ITEM_COUNT\n",
    "Xu=sparse.coo_matrix((V,(coupon_id,user_id)),shape=(num_item,num_user)) # the user_id looks like (1,1,1,2,2,3,4,4,...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#negative row indexs\n",
    "# transform the hash code to natural index in df_coupon_train\n",
    "df_coupon_visit.drop(labels=[u'I_DATE',u'PAGE_SERIAL',u'REFERRER_hash',u'SESSION_ID_hash',u'PURCHASEID_hash'],axis=1,inplace=True)\n",
    "#g_visit=df_coupon_visit.groupby('VIEW_COUPON_ID_hash')\n",
    "#g_visit.count()\n",
    "g_visit2=df_coupon_visit.groupby(['VIEW_COUPON_ID_hash','USER_ID_hash'])\n",
    "#df_rating=pd.DataFrame(g_visit2.apply(lambda x: np.sum(x['PURCHASE_FLG'])))\n",
    "df_rating=df_coupon_visit[[u'USER_ID_hash',u'VIEW_COUPON_ID_hash','PURCHASE_FLG']] #duplicate coupon??????\n",
    "df_user['user_global_index']=df_user.index # all the users now has a unique index\n",
    "df_coupon_train['coupon_global_index']=df_coupon_train.index # all the coupons in training set now has a unique index\n",
    "#df_CouponProperty=pd.concat([df_coupon_train,df_coupon_test])\n",
    "# build up user global index and coupon global index for row and column index for sparse matrix\n",
    "user_id=df_user.set_index('USER_ID_hash').loc[df_rating['USER_ID_hash']]['user_global_index'].values\n",
    "coupon_id=df_coupon_train.set_index('COUPON_ID_hash').loc[df_rating['VIEW_COUPON_ID_hash']]['coupon_global_index'].values\n",
    "num_item,num_user=len(df_coupon_train.COUPON_ID_hash.unique()),len(df_user.USER_ID_hash.unique())\n",
    "V=df_rating.PURCHASE_FLG\n",
    "Xu=sparse.coo_matrix((V,(coupon_id,user_id)),shape=(num_item,num_user)) # the user_id looks like (1,1,1,2,2,3,4,4,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_rating=pd.DataFrame(g_visit2.agg(lambda x: np.sum(x['PURCHASE_FLG'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_list = [('item_feature', Get_coupon_feature())]\n",
    "fu_obj = FeatureUnion(transformer_list=feature_list)\n",
    "Xs=fu_obj.fit_transform(pd.concat([df_coupon_train,df_coupon_test],axis=0)) # df_coupon_train is already the natural global index for items\n",
    "Xs_train=Xs[0:19413,:]\n",
    "Xs_test=Xs[19413:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.nonzero(Xs[0:19413,-1]),np.nonzero(Xs[19413:19413+310,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_coupon_train.shape,df_coupon_test.shape,Xs.shape,Xs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#the following is not good way to transform hash code to index\n",
    "'''\n",
    "userIndex=label_encoder.fit_transform(df_user.USER_ID_hash.unique())\n",
    "J=label_encoder.transform(df_rating.USER_ID_hash)\n",
    "itemIndex=label_encoder.fit_transform(df_coupon_train.COUPON_ID_hash.unique())\n",
    "I=label_encoder.transform(df_rating.COUPON_ID_hash)\n",
    "V=df_rating.ITEM_COUNT\n",
    "Xu= sparse.coo_matrix((V,(I,J)),shape=(len(itemIndex),len(userIndex)))\n",
    "'''\n",
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('Xstr_Xu_Xs_te.pickle', 'wb') as f:\n",
    "            pickle.dump((Xs_train,Xu,Xs_test), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Xstr_Xu_Xs_te.pickle', 'rb') as f:\n",
    "    Xs_train,Xu,Xs_test=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19413, 163), (19413, 22873), (310, 163))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_train.shape,Xu.shape,Xs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lce\n",
    "reload(lce)\n",
    "OBJ=lce.LCE()\n",
    "OBJ.run(sparse.coo_matrix(Xs),Xu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#joint three dataframes: df_coupon_visit*df_coupon_train(coupon information)*df_user(user information)\n",
    "train_df = pd.merge(df_coupon_visit, df_coupon_train,left_on=\"VIEW_COUPON_ID_hash\", right_on=\"COUPON_ID_hash\")\n",
    "train_df = pd.merge(train_df, df_user,left_on=\"USER_ID_hash\", right_on=\"USER_ID_hash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_list = [('item_feature', Get_coupon_feature()),('user_item',Get_Match_Pref()),('getUserFeature',Get_user_feature())]\n",
    "fu_obj = FeatureUnion(transformer_list=feature_list)\n",
    "X_train = fu_obj.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = train_df[\"PURCHASE_FLG\"]\n",
    "assert X_train.shape[0] == y_train.size\n",
    "# fit model\n",
    "from sklearn import ensemble\n",
    "original_params = {'n_estimators': 1000,'n_jobs':-1}\n",
    "params = dict(original_params)\n",
    "clf=ensemble.RandomForestClassifier(**params)\n",
    "#clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "# create test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generate the Cartesian Product\n",
    "df_coupon_test[\"cross\"] = 1 # all test items are new, ie, cold-start items\n",
    "df_user[\"cross\"] = 1 # all users are old\n",
    "test_df_item_user = pd.merge(df_coupon_test,df_user, on=\"cross\")\n",
    "# create test Feature\n",
    "X_test = fu_obj.transform(test_df_item_user)\n",
    "# predict test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_proba = clf.predict_proba(X_test)\n",
    "pos_idx = np.where(clf.classes_ == True)[0][0] # find out which column is positive\n",
    "test_df_item_user[\"predict\"] = predict_proba[:, pos_idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top10_coupon=test_df_item_user.groupby(\"USER_ID_hash\").apply(extract_topn_item4user) #for each user\n",
    "top10_coupon.name = \"PURCHASED_COUPONS\"\n",
    "top10_coupon.to_csv(\"submission.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "X_train.shape,y_train.shape\n",
    "pd.unique(df_coupon_train.USABLE_DATE_FRI)\n",
    "df_rating['user_global_index'] = pd.Series(user_id, index=df_rating.index)\n",
    "df_rating['coupon_global_index']=pd.Series(coupon_id, index=df_rating.index)\n",
    "df_rating=df_rating.drop(labels=['USER_ID_hash','COUPON_ID_hash'],axis=1)\n",
    "df_rating2['user_global_index'] = pd.Series(user_id, index=df_rating.index)\n",
    "df_rating['coupon_global_index']=pd.Series(coupon_id, index=df_rating.index)\n",
    "df_rating=df_rating.drop(labels=['USER_ID_hash','COUPON_ID_hash'],axis=1)\n",
    "pd.Series(coupon_id).hist()\n",
    "df_rating2[['USER_ID_hash','VIEW_COUPON_ID_hash','PURCHASE_FLG']].describe()\n",
    "df_CouponProperty=pd.read_csv('coupon_list_train.csv')\n",
    "\n",
    "trainCouponSet=set(df_coupon_train.COUPON_ID_hash.unique()) import lce eng=lce.LCE() testCouponSet=set(df_coupon_test.COUPON_ID_hash.unique()) len(trainCouponSet) len(testCouponSet) df_coupon_buy.ITEM_COUNT.unique() trainCouponSet.intersection(testCouponSet) len(set(df_coupon_visit.VIEW_COUPON_ID_hash.unique()).intersection(set(df_coupon_buy.COUPON_ID_hash.unique()))) trainCouponSet.intersection(set(df_coupon_visit.VIEW_COUPON_ID_hash.unique()))\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from scipy.sparse import spdiags\n",
    "data = np.array([[1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]])\n",
    "diags = np.array([0, -1, 2])\n",
    "data*data\n",
    "np.multiply(data,data)\n",
    "data,sp*data\n",
    "1. / (np.sqrt(np.sum(np.multiply(data,data), axis=1)))\n",
    "sp=sparse.spdiags(1./np.sqrt(np.sum(data * data, axis=1)),0,data.shape[0],data.shape[0])\n",
    "sp.todense()*data\n",
    "np.sum(data,axis=1)\n",
    "####################################\n",
    "sparse.coo_matrix.multiply(Xu,Xu.toarray())\n",
    "\n",
    "Xu.sum(1).shape\n",
    "(1. / (np.sqrt(Xu.multiply(Xu).sum(1)) )).shape\n",
    "1. / np.sqrt((Xu.multiply(Xu).sum(1)) ).T\n",
    "sparse.spdiags((1. / np.sqrt((Xu.multiply(Xu).sum(1)) )).T, 0, Xu.shape[0], Xu.shape[0]).todense()\n",
    "sparse.spdiags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row  = np.array([0, 3, 1, 0])\n",
    "col  = np.array([0, 3, 1, 2])\n",
    "data = np.array([4, 5, 7, 9])\n",
    "A=sparse.coo_matrix((data, (row, col)), shape=(4, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row = np.array([0, 2, 2, 0 ])\n",
    "col = np.array([0, 0, 1, 2])\n",
    "data = np.array([1.0, 2.0, 3.0, 4.0])\n",
    "B=sparse.csc_matrix((data, (row, col)), shape=(4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AA=sparse.csc_matrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BB=sparse.csc_matrix(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparse.csc_matrix.multiply(AA,BB.T).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BB.todense(),AA.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(BB+BB).todense(),BB.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(scipy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.maximum(BB.toarray(),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparse.csc_matrix.maximum(BB,1).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " print(\"Hu is %s\" %BB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BB.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(BB.diagonal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_coupon_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('Xs_test.pickle', 'wb') as f:\n",
    "    pickle.dump(Xs_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
